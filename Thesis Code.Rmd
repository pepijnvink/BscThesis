---
title: "Thesis Practice"
author: "Pepijn Vink"
date: "3/6/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages

```{r load-libraries, message = FALSE}
library(BayesFactor)
library(tidyverse)
library(magrittr)
library(jtools)
library(bayestestR)
library(gmodels)
library(BRRR)
library(skimr)
library(tidybayes)
library(patchwork)
library(pwr)
```

Load function to make simulation more smooth. BF 'cutoffs' and evidence levels are based on Jeffrey's (1961). For p values, CI's and HDI's, 1 indicates rejection of the null and 0 no rejection. For the BF's at every cutoff value, 0 indicates preference for the null, 1 indicates no preference, and 2 indicates preference for the alternative/complement. Posterior probabilities are based on equal prior odds.

```{r load-function}
source("freq.bayes.R")
```

# Set theme
```{r}
apatheme <- theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        plot.title = element_text(size = 12,
                                  family = "Times"),
        text = element_text(size = 12,
                            family = 'Times'),
        legend.title = element_blank(),
        axis.text.y = element_text(size = 12,
                                   family = "Times"),
        axis.text.x = element_text(size = 12,
                                   family = "Times"))
```


# Simulate different sample sizes

## Power analysis to determine samle size for power of 50% and 80%

```{r power-analysis}
pwr.t.test(d = 0.5, power = 0.5, type = "two.sample", alternative = "two.sided")
pwr.t.test(d = 0.5, power = 0.8, type = "two.sample", alternative = "two.sided")
```

## No effect

```{r simulate-null, message = FALSE}
set.seed(42)

# n = 10
df0.n10 <- as.data.frame(freq.bayes(sample.size = 10, iterations = 10000))

# n = 32
df0.n32 <- as.data.frame(freq.bayes(sample.size = 32, iterations = 10000))

# n = 64
df0.n64 <- as.data.frame(freq.bayes(sample.size = 64, iterations = 10000))

# n = 100
df0.n100 <- as.data.frame(freq.bayes(sample.size = 100, iterations = 10000))

# n = 300
df0.n300 <- as.data.frame(freq.bayes(sample.size = 300, iterations = 10000))

# n = 500
df0.n500 <- as.data.frame(freq.bayes(sample.size = 500, iterations = 10000))
```


## Medium effect (delta = 0.5, difference = 5)

```{r simulate-effect, message = FALSE}
set.seed(69)

# n = 10
df.n10 <- as.data.frame(freq.bayes(sample.size = 10, iterations = 10000, difference = 5))

# n = 32
df.n32 <- as.data.frame(freq.bayes(sample.size = 32, iterations = 10000, difference = 5))

# n = 64
df.n64 <- as.data.frame(freq.bayes(sample.size = 64, iterations = 10000, difference = 5))

# n = 100
df.n100 <- as.data.frame(freq.bayes(sample.size = 100, iterations = 10000, difference = 5))

# n = 300
df.n300 <- as.data.frame(freq.bayes(sample.size = 300, iterations = 10000, difference = 5))

# n = 500
df.n500 <- as.data.frame(freq.bayes(sample.size = 500, iterations = 10000, difference = 5))
```


## Combine results for null

```{r}
df0 <- rbind(df0.n10, df0.n32, df0.n64, df0.n100, df0.n300, df0.n500)

# Convert relevant columns to numeric
df0[c(1:15, 28, 29, 33, 34)] <- sapply(df0[c(1:15, 28, 29, 33, 34)], as.numeric)

## Convert BF.evidence, n, and difference to factor
df0$BF.evidence <- as.factor(df0$BF.evidence)
df0$n_num <- df0$n
df0$n <- as.factor(df0$n) %>% fct_relevel(c("10", "32", "64", "300", "100", "500"))
df0$BF3.decision <- as_factor(df0$BF3.decision) %>% fct_relevel(c("null", "U", "alt"))
df0$BF10.decision <- as_factor(df0$BF10.decision) %>% fct_relevel(c("null", "U", "alt"))
df0$BF30.decision <- as_factor(df0$BF30.decision) %>% fct_relevel(c("null", "U", "alt"))
df0$p.decision <- as_factor(df0$p.decision) %>% fct_relevel(c("null", "alt"))
df0$p.correct <- as.factor(case_when(df0$p <= .05 & df0$difference > 0 & df0$diff_obs  > 0 ~ "correct",
                          df0$p <= .05 & df0$difference < 0 & df0$diff_obs  < 0 ~ "correct",
                          df0$p > .05 & df0$difference == 0 ~ "correct",
                          TRUE ~ "incorrect"))
df0$HDI.correct <- as.factor(case_when(df0$HDI.decision == "null" & df0$difference == 0 ~ "correct",
                                       df0$HDI.decision == "alt" & df0$difference > 0 & df0$diff_obs > 0 ~ "correct",
                                       df0$HDI.decision == "alt" & df0$difference < 0 & df0$diff_obs < 0 ~ "correct",
                                       TRUE ~ "incorrect"))
df0$BF1.correct <- as.factor(case_when(df0$BF1.decision == "null" & df0$difference == 0 ~ "correct",
                                       df0$BF1.decision == "alt" & df0$difference > 0 & df0$diff_obs > 0 ~ "correct",
                                       df0$BF1.decision == "alt" & df0$difference < 0 & df0$diff_obs < 0 ~ "correct",
                                       TRUE ~ "incorrect"))
df0$difference <- as.factor(df0$difference) 
df0$BF.3.cor <- as_factor(df0$BF.3.cor) %>% fct_relevel(c("incorrect", "correct"))
df0$BF.10.cor <- as_factor(df0$BF.10.cor) %>% fct_relevel(c("incorrect", "correct"))
df0$BF.30.cor <- as_factor(df0$BF.30.cor) %>% fct_relevel(c("incorrect", "correct"))
df0$BF.3.ninc <- as_factor(df0$BF.3.ninc) %>% fct_relevel(c("incorrect", "correct"))
df0$BF.10.ninc <- as_factor(df0$BF.10.ninc) %>% fct_relevel(c("incorrect", "correct"))
df0$BF.30.ninc <- as_factor(df0$BF.30.ninc) %>% fct_relevel(c("incorrect", "correct"))
df0$BF1.decision <- as_factor(df0$BF1.decision) %>% fct_relevel(c("null", "alt"))
df0$HDI.decision <- as_factor(df0$HDI.decision)  %>% fct_relevel(c("null", "alt"))
df0$HDI.est.correct <- as_factor(df0$HDI.est.correct) %>% fct_relevel(c("incorrect", "correct"))
df0$CI.est.correct <- as_factor(df0$CI.est.correct) %>% fct_relevel(c("incorrect", "correct"))
```

## Combine results for delta = .5

```{r}
df <- rbind(df.n10, df.n32, df.n64, df.n100, df.n300, df.n500)

# Convert relevant columns to numeric
df[c(1:15, 28, 29, 33, 34)] <- sapply(df[c(1:15, 28, 29, 33, 34)], as.numeric)

## Convert BF.evidence, n, and difference to factor
df$BF.evidence <- as.factor(df$BF.evidence)
df$n_num <- df$n
df$n <- as.factor(df$n) %>% fct_relevel(c("10", "32", "64", "300", "100", "500"))
df$BF3.decision <- as.factor(df$BF3.decision) %>% fct_relevel(c("null", "U", "alt"))
df$BF10.decision <- as.factor(df$BF10.decision) %>% fct_relevel(c("null", "U", "alt"))
df$BF30.decision <- as.factor(df$BF30.decision) %>% fct_relevel(c("null", "U", "alt"))
df$p.decision <- as.factor(df$p.decision) %>% fct_relevel(c("null", "alt"))
df$p.correct <- as.factor(case_when(df$p <= .05 & df$difference > 0 & df$diff_obs  > 0 ~ "correct",
                          df$p <= .05 & df$difference < 0 & df$diff_obs  < 0 ~ "correct",
                          df$p > .05 & df$difference == 0 ~ "correct",
                          TRUE ~ "incorrect"))
df$HDI.correct <- as.factor(case_when(df$HDI.decision == "null" & df$difference == 0 ~ "correct",
                                       df$HDI.decision == "alt" & df$difference > 0 & df$diff_obs > 0 ~ "correct",
                                       df$HDI.decision == "alt" & df$difference < 0 & df$diff_obs < 0 ~ "correct",
                                       TRUE ~ "incorrect"))
df$BF1.correct <- as.factor(case_when(df$BF1.decision == "null" & df$difference == 0 ~ "correct",
                                       df$BF1.decision == "alt" & df$difference > 0 & df$diff_obs > 0 ~ "correct",
                                       df$BF1.decision == "alt" & df$difference < 0 & df$diff_obs < 0 ~ "correct",
                                       TRUE ~ "incorrect"))
df$difference <- as.factor(df$difference)
df$BF.3.cor <- as_factor(df$BF.3.cor) %>% fct_relevel(c("incorrect", "correct"))
df$BF.10.cor <- as_factor(df$BF.10.cor) %>% fct_relevel(c("incorrect", "correct"))
df$BF.30.cor <- as_factor(df$BF.30.cor) %>% fct_relevel(c("incorrect", "correct"))
df$BF.3.ninc <- as_factor(df$BF.3.ninc) %>% fct_relevel(c("incorrect", "correct"))
df$BF.10.ninc <- as_factor(df$BF.10.ninc) %>% fct_relevel(c("incorrect", "correct"))
df$BF.30.ninc <- as_factor(df$BF.30.ninc) %>% fct_relevel(c("incorrect", "correct"))
df$BF1.decision <- as_factor(df$BF1.decision) %>% fct_relevel(c("null", "alt"))
df$HDI.decision <- as.factor(df$HDI.decision)  %>% fct_relevel(c("null", "alt"))
df$HDI.est.correct <- as.factor(df$HDI.est.correct) %>% fct_relevel(c("incorrect", "correct"))
df$CI.est.correct <- as.factor(df$CI.est.correct) %>% fct_relevel(c("incorrect", "correct"))
```

# Visualizations

## Visualize p-value distributions

```{r}
(p.dis.n10 <- ggplot(df[df$n == 10,], aes(p)) + geom_histogram(bins = 100) + theme_apa() + scale_fill_grey())
(p.dis.n32 <- ggplot(df[df$n == 32,], aes(p)) + geom_histogram(bins = 100) + theme_apa() + scale_fill_grey())
(p.dis.n64 <- ggplot(df[df$n == 64,], aes(p)) + geom_histogram(bins = 100) + theme_apa() + scale_fill_grey())
(p.dis.n100 <- ggplot(df[df$n == 100,], aes(p)) + geom_histogram(bins = 100) + theme_apa() + scale_fill_grey())
(p.dis.n500 <- ggplot(df[df$n == 500,], aes(p)) + geom_histogram(bins = 100) + theme_apa() + scale_fill_grey())

(p.distributions <-
  p.dis.n10/
  p.dis.n32/
  p.dis.n64/
  p.dis.n100/
  p.dis.n500)
```

## Visualize p correct and BF correct for null

```{r}
p.correct.percentage.0 <- df0 %>%
  group_by(n_num, p.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF1.correct.percentage.0 <- df0 %>%
  group_by(n_num, BF1.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

HDI.correct.percentage.0 <- df0 %>%
  group_by(n_num, HDI.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF3.correct.percentage.0 <- df0 %>%
  group_by(n_num, BF.3.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)
  

BF10.correct.percentage.0 <- df0 %>%
  group_by(n_num, BF.10.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

correct.rows.BF30.cor0 <- data.frame(c(10, 32, 64, 100, 300, 500),
        c("correct", "correct", "correct", "correct", "correct", "correct"),
        c(0, 0, 0, 0, 0, 0 ),
        c(0, 0, 0, 0, 0, 0),
        c(0, 0, 0, 0, 0, 0))

names(correct.rows.BF30.cor0) <- c("n_num", "BF.30.cor", "N", "freq", "pct")

BF30.correct.percentage.0 <- df0 %>%
  group_by(n_num, BF.30.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100) %>%
  as.data.frame() %>%
  plyr::rbind.fill(correct.rows.BF30.cor0)
BF30.correct.percentage.0$BF.30.cor <- as_factor(BF30.correct.percentage.0$BF.30.cor)

ggplot(NULL, aes(x = n_num, y = pct)) + 
  ylim(0, 100) +
  geom_point(data = p.correct.percentage.0[p.correct.percentage.0$p.correct == "correct" & p.correct.percentage.0$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_line(data = p.correct.percentage.0[p.correct.percentage.0$p.correct == "correct" & p.correct.percentage.0$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_point(data = HDI.correct.percentage.0[HDI.correct.percentage.0$HDI.correct == "correct" & HDI.correct.percentage.0$n_num < 2000, ], aes(color = "HDI")) +
  geom_line(data = HDI.correct.percentage.0[HDI.correct.percentage.0$HDI.correct == "correct" & HDI.correct.percentage.0$n_num < 2000, ], aes(color = "HDI")) +
  geom_point(data = BF1.correct.percentage.0[BF1.correct.percentage.0$BF1.correct == "correct" & BF1.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_line(data = BF1.correct.percentage.0[BF1.correct.percentage.0$BF1.correct == "correct" & BF1.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_point(data = BF3.correct.percentage.0[BF3.correct.percentage.0$BF.3.cor == "correct" & BF3.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_line(data = BF3.correct.percentage.0[BF3.correct.percentage.0$BF.3.cor == "correct" & BF3.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_point(data = BF10.correct.percentage.0[BF10.correct.percentage.0$BF.10.cor == "correct" & BF10.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_line(data = BF10.correct.percentage.0[BF10.correct.percentage.0$BF.10.cor == "correct" & BF10.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 10")) +
 scale_colour_manual("", 
                      breaks = c("p < .05", "HDI", "BF > 1", "BF > 3", "BF > 10", "BF > 30"),
                      values = c("black", "blue", "pink", "orange", "red", "purple")) +
  apatheme +
  scale_x_continuous(name = "Sample Size", breaks = c(10, 32, 64, 100, 300, 500, 2000)) +
  ylab("Percentage of Correct Samples")
```

## Visualize incorrect p and BF decisions for null

```{r}
BF3.incorrect.percentage.0 <- df0 %>%
  group_by(n_num, BF.3.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)
  
BF10.incorrect.percentage.0 <- df0 %>%
group_by(n_num, BF.10.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF30.incorrect.percentage.0 <- df0 %>%
  group_by(n_num, BF.30.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

ggplot(NULL, aes(x = n_num, y = pct)) + 
  ylim(0, 20) +
  geom_point(data = p.correct.percentage.0[p.correct.percentage.0$p.correct == "incorrect" & p.correct.percentage.0$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_line(data = p.correct.percentage.0[p.correct.percentage.0$p.correct == "incorrect" & p.correct.percentage.0$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_point(data = HDI.correct.percentage.0[HDI.correct.percentage.0$HDI.correct == "incorrect" & HDI.correct.percentage.0$n_num < 2000, ], aes(color = "HDI")) +
  geom_line(data = HDI.correct.percentage.0[HDI.correct.percentage.0$HDI.correct == "incorrect" & HDI.correct.percentage.0$n_num < 2000, ], aes(color = "HDI")) +
  geom_point(data = BF1.correct.percentage.0[BF1.correct.percentage.0$BF1.correct == "incorrect" & BF1.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_line(data = BF1.correct.percentage.0[BF1.correct.percentage.0$BF1.correct == "incorrect" & BF1.correct.percentage.0$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_point(data = BF3.incorrect.percentage.0[BF3.incorrect.percentage.0$BF.3.ninc == "incorrect" & BF3.incorrect.percentage.0$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_line(data = BF3.incorrect.percentage.0[BF3.incorrect.percentage.0$BF.3.ninc == "incorrect" & BF3.incorrect.percentage.0$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_point(data = BF10.incorrect.percentage.0[BF10.incorrect.percentage.0$BF.10.ninc == "incorrect" & BF10.incorrect.percentage.0$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_line(data = BF10.incorrect.percentage.0[BF10.incorrect.percentage.0$BF.10.ninc == "incorrect" & BF10.incorrect.percentage.0$n_num < 2000, ], aes(color = "BF > 10")) +
  scale_colour_manual("", 
                      breaks = c("p < .05", "HDI", "BF > 1", "BF > 3", "BF > 10", "BF > 30"),
                      values = c("black", "blue", "pink", "orange", "red", "purple")) +
  apatheme +
  scale_x_continuous(name = "Sample Size", breaks = c(10, 32, 64, 100, 300, 500, 2000)) +
  ylab("Percentage of Incorrect Samples")
```

## Visualize p correct and BF correct for alt

```{r}
p.correct.percentage <- df %>%
  group_by(n_num, p.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF1.correct.percentage <- df %>%
  group_by(n_num, BF1.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

HDI.correct.percentage <- df %>%
  group_by(n_num, HDI.correct, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF3.correct.percentage <- df %>%
  group_by(n_num, BF.3.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF10.correct.percentage <- df %>%
group_by(n_num, BF.10.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF30.correct.percentage <- df %>%
  group_by(n_num, BF.30.cor, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

ggplot(NULL, aes(x = n_num, y = pct)) + 
  ylim(0, 100) +
  geom_point(data = p.correct.percentage[p.correct.percentage$p.correct == "correct" & p.correct.percentage$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_line(data = p.correct.percentage[p.correct.percentage$p.correct == "correct" & p.correct.percentage$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_point(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "correct" & HDI.correct.percentage$n_num < 2000, ], aes(color = "HDI")) +
  geom_line(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "correct" & HDI.correct.percentage$n_num < 2000, ], aes(color = "HDI")) +
  geom_point(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "correct" & BF1.correct.percentage$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_line(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "correct" & BF1.correct.percentage$n_num < 2000, ], aes(color = "BF > 1")) +
  geom_point(data = BF3.correct.percentage[BF3.correct.percentage$BF.3.cor == "correct" & BF3.correct.percentage$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_line(data = BF3.correct.percentage[BF3.correct.percentage$BF.3.cor == "correct" & BF3.correct.percentage$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_point(data = BF10.correct.percentage[BF10.correct.percentage$BF.10.cor == "correct" & BF10.correct.percentage$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_line(data = BF10.correct.percentage[BF10.correct.percentage$BF.10.cor == "correct" & BF10.correct.percentage$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_point(data = BF30.correct.percentage[BF30.correct.percentage$BF.30.cor == "correct" & BF30.correct.percentage$n_num < 2000, ], aes(color = "BF > 30")) +
  geom_line(data = BF30.correct.percentage[BF30.correct.percentage$BF.30.cor == "correct" & BF30.correct.percentage$n_num < 2000, ], aes(color = "BF > 30")) +
  scale_colour_manual("", 
                      breaks = c("p < .05", "HDI", "BF > 1", "BF > 3", "BF > 10", "BF > 30"),
                      values = c("black", "blue", "pink", "orange", "red", "purple")) +
  apatheme +
  scale_x_continuous(name = "Sample Size", breaks = c(10, 32, 64, 100, 300, 500)) +
  ylab("Percentage of Correct Samples")
```

## Above without 10 and 30 as cutoffs

```{r}
ggplot(NULL, aes(x = n_num, y = pct)) + 
  ylim(0, 100) +
  geom_point(data = p.correct.percentage[p.correct.percentage$p.correct == "correct", ], aes(color = "p < .05")) + 
  geom_line(data = p.correct.percentage[p.correct.percentage$p.correct == "correct", ], aes(color = "p < .05")) + 
  geom_point(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "correct", ], aes(color = "HDI")) +
  geom_line(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "correct", ], aes(color = "HDI")) +
  geom_point(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "correct", ], aes(color = "BF > 1")) + 
  geom_line(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "correct", ], aes(color = "BF > 1")) +
  geom_point(data = BF3.correct.percentage[BF3.correct.percentage$BF.3.cor == "correct", ], aes(color = "BF > 3")) +
  geom_line(data = BF3.correct.percentage[BF3.correct.percentage$BF.3.cor == "correct", ], aes(color = "BF > 3")) +
  scale_colour_manual("", 
                      breaks = c("p < .05", "HDI", "BF > 1", "BF > 3"),
                      values = c("black", "blue", "pink", "orange")) +
  apatheme +
  scale_x_continuous(name = "Sample Size", breaks = c(10, 32, 64, 100, 300, 500)) +
  ylab("Percentage of Correct Samples")
```

## Visualize incorrect p and BF decisions for alt

```{r}
incorrect.rows.BF10.incor <- data.frame(c(10, 32, 64, 100, 300, 500),
        c("incorrect", "incorrect", "incorrect", "incorrect", "incorrect", "incorrect"),
        c(0, 0, 0, 0, 0, 0),
        c(0, 0, 0, 0, 0, 0),
        c(0, 0, 0, 0, 0, 0))

names(incorrect.rows.BF10.incor) <- c("n_num", "BF.10.ninc", "N", "freq", "pct")

incorrect.rows.BF30.incor <- data.frame(c(10, 32, 64, 100, 300, 500),
        c("incorrect", "incorrect", "incorrect", "incorrect", "incorrect", "incorrect"),
        c(0, 0, 0, 0, 0, 0),
        c(0, 0, 0, 0, 0, 0),
        c(0, 0, 0, 0, 0, 0))

names(incorrect.rows.BF30.incor) <- c("n_num", "BF.30.ninc", "N", "freq", "pct")

BF3.incorrect.percentage <- df %>%
  group_by(n_num, BF.3.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)

BF10.incorrect.percentage <- df %>%
group_by(n_num, BF.10.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100)  %>%
  as.data.frame() %>%
  plyr::rbind.fill(incorrect.rows.BF10.incor)

BF10.incorrect.percentage$BF.10.ninc <- as_factor(BF10.incorrect.percentage$BF.10.ninc)

BF30.incorrect.percentage <- df %>%
  group_by(n_num, BF.30.ninc, .drop = FALSE) %>%
  summarize(N = n()) %>%
  mutate(freq = N/sum(N),
         pct = freq*100) %>%
  as.data.frame() %>%
  plyr::rbind.fill(incorrect.rows.BF30.incor)

BF30.incorrect.percentage$BF.30.ninc <- as_factor(BF30.incorrect.percentage$BF.30.ninc)

ggplot(NULL, aes(x = n_num, y = pct)) + 
  ylim(0, 100) +
  geom_point(data = p.correct.percentage[p.correct.percentage$p.correct == "incorrect" & p.correct.percentage$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_line(data = p.correct.percentage[p.correct.percentage$p.correct == "incorrect" & p.correct.percentage$n_num < 2000, ], aes(color = "p < .05")) + 
  geom_point(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "incorrect" & HDI.correct.percentage$n_num < 2000, ], aes(color = "HDI")) +
  geom_line(data = HDI.correct.percentage[HDI.correct.percentage$HDI.correct == "incorrect" & HDI.correct.percentage$n_num < 2000, ], aes(color = "HDI")) +
  geom_point(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "incorrect" & BF1.correct.percentage$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_line(data = BF1.correct.percentage[BF1.correct.percentage$BF1.correct == "incorrect" & BF1.correct.percentage$n_num < 2000, ], aes(color = "BF > 1")) + 
  geom_point(data = BF3.incorrect.percentage[BF3.incorrect.percentage$BF.3.ninc == "incorrect" & BF3.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_line(data = BF3.incorrect.percentage[BF3.incorrect.percentage$BF.3.ninc == "incorrect" & BF3.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 3")) +
  geom_point(data = BF10.incorrect.percentage[BF10.incorrect.percentage$BF.10.ninc == "incorrect" & BF10.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_line(data = BF10.incorrect.percentage[BF10.incorrect.percentage$BF.10.ninc == "incorrect" & BF10.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 10")) +
  geom_point(data = BF30.incorrect.percentage[BF30.incorrect.percentage$BF.30.ninc == "incorrect" & BF30.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 30")) +
  geom_line(data = BF30.incorrect.percentage[BF30.incorrect.percentage$BF.30.ninc == "incorrect" & BF30.incorrect.percentage$n_num < 2000, ], aes(color = "BF > 30")) +
  scale_colour_manual("", 
                      breaks = c("p < .05", "HDI", "BF > 1", "BF > 3", "BF > 10", "BF > 30"),
                      values = c("black", "blue", "pink", "orange", "red", "purple")) +
  apatheme +
  scale_x_continuous(name = "Sample Size", breaks = c(10, 32, 64, 100, 300, 500)) +
  ylab("Percentage of Incorrect Samples")
```

## Examine precision of confidence interval and HDI

```{r}
width <- df %>%
  group_by(n) %>%
  select("ci.width", "hdi.width") %>%
  skim()
```

Create density plots for null

```{r}
width.plot0.10 <- data.frame(x = c(df0[df0$n == 10,]$ci.width, df0[df0$n == 10,]$hdi.width), 
                             type = rep(c("Confidence Interval", "HDI"), 
                                      c(length(df0[df0$n == 10,]$ci.width), 
                                        length(df0[df0$n == 10,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) +
  scale_fill_grey() +
  ggtitle("n = 10") +
  xlab("Interval Width") +
  apatheme

width.plot0.32 <- data.frame(x = c(df0[df0$n == 32,]$ci.width, df0[df0$n == 32,]$hdi.width), 
                             type = rep(c("Confidence Interval", "HDI"), 
                                        c(length(df0[df0$n == 32,]$ci.width), 
                                          length(df0[df0$n == 32,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) +
  scale_fill_grey() +
  ggtitle("n = 32") +
  xlab("Interval Width") +
  apatheme

width.plot0.64 <- data.frame(x = c(df0[df0$n == 64,]$ci.width, df0[df0$n == 64,]$hdi.width),
                             type = rep(c("Confidence Interval", "HDI"),
                                        c(length(df0[df0$n == 64,]$ci.width), 
                                          length(df0[df0$n == 64,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) +
  scale_fill_grey() +
  ggtitle("n = 64") +
  xlab("Interval Width") +
  apatheme

width.plot0.100 <- data.frame(x = c(df0[df0$n == 100,]$ci.width, df0[df0$n == 100,]$hdi.width), 
                              type=rep(c("Confidence Interval", "HDI"), 
                                       c(length(df0[df0$n == 100,]$ci.width), 
                                         length(df0[df0$n == 100,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) +
  scale_fill_grey() +
  ggtitle("n = 100") +
  xlab("Interval Width") +
  apatheme

width.plot0.300 <- data.frame(x = c(df0[df0$n == 300,]$ci.width, df0[df0$n == 300,]$hdi.width), 
                              type=rep(c("Confidence Interval", "HDI"), 
                                       c(length(df0[df0$n == 300,]$ci.width), 
                                         length(df0[df0$n == 300,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  scale_fill_grey() +
  ggtitle("n = 300") +
  xlab("Interval Width") +
  apatheme

width.plot0.500 <- data.frame(x = c(df0[df0$n == 500,]$ci.width, df0[df0$n == 500,]$hdi.width), 
                              type=rep(c("Confidence Interval", "HDI"), 
                                       c(length(df0[df0$n == 500,]$ci.width), 
                                         length(df0[df0$n == 500,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  scale_fill_grey() +
  ggtitle("n = 500") +
  xlab("Interval Width") +
  apatheme

width_plot0 <- width.plot0.10/
width.plot0.32/
width.plot0.64/
width.plot0.100

width_plot0 <- width_plot0 + plot_layout(guides = "collect")  & xlim(0, 30)
width_plot0
```
Create density plots for delta = 0.5

```{r}
width.plot.10 <- data.frame(x = c(df[df$n == 10,]$ci.width, df[df$n == 10,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 10,]$ci.width), 
                                       length(df[df$n == 10,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  scale_fill_grey() +
  ggtitle("n = 10") +
  xlab("Interval Width") +
  apatheme

width.plot.32 <- data.frame(x = c(df[df$n == 32,]$ci.width, df[df$n == 32,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 32,]$ci.width), 
                                       length(df[df$n == 32,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  scale_fill_grey() +
  ggtitle("n = 32") +
  xlab("Interval Width") +
  apatheme

width.plot.64 <- data.frame(x = c(df[df$n == 64,]$ci.width, df[df$n == 64,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 64,]$ci.width), 
                                       length(df[df$n == 64,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  theme_apa() + 
  scale_fill_grey() +
  ggtitle("n = 64") +
  xlab("Interval Width") +
  apatheme

width.plot.100 <- data.frame(x = c(df[df$n == 100,]$ci.width, df[df$n == 100,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 100,]$ci.width), 
                                       length(df[df$n == 100,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  theme_apa() + 
  scale_fill_grey() +
  ggtitle("n = 100") +
  xlab("Interval Width") +
  apatheme

width.plot.300 <- data.frame(x = c(df[df$n == 300,]$ci.width, df[df$n == 300,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 300,]$ci.width), 
                                       length(df[df$n == 300,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  theme_apa() + 
  scale_fill_grey() +
  ggtitle("n = 300") +
  xlab("Interval Width") +
  apatheme

width.plot.500 <- data.frame(x = c(df[df$n == 500,]$ci.width, df[df$n == 500,]$hdi.width), 
                            type=rep(c("Confidence Interval", "HDI"), 
                                     c(length(df[df$n == 500,]$ci.width), 
                                       length(df[df$n == 500,]$hdi.width)))) %>%
  ggplot() + 
  geom_density(aes(x=x, fill=type), alpha = 0.5) + 
  theme_apa() + 
  scale_fill_grey() +
  ggtitle("n = 500") +
  xlab("Interval Width") +
  apatheme

width_plot <- width.plot.10/
width.plot.32/
width.plot.64/
width.plot.100

width_plot <- width_plot + plot_layout(guides = "collect") & xlim(0, 30)
width_plot
```


## Show corresponding conclusions for null

```{r}
# Set alpha and size -----------------------------------------------------------
a <- 0.2
s <- 0.1

# For p values and Bayes factor cutoffs-----------------------------------------
(bf3.p.plot.0 <- ggplot(df0, aes(x = BF3.decision, y = p.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

(bf10.p.plot.0 <- ggplot(df0, aes(x = BF10.decision, y = p.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf30.p.plot.0 <- ggplot(df0, aes(x = BF30.decision, y = p.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf.p.plot.0 <- 
  bf3.p.plot.0/
  bf10.p.plot.0/
  bf30.p.plot.0)

# For HDI and BF cutoffs --------------------------------------------------------

(bf3.hdi.plot.0 <- ggplot(df0, aes(x = BF3.decision, y = HDI.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   theme_apa() + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

(bf10.hdi.plot.0 <- ggplot(df0, aes(x = BF10.decision, y = HDI.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf30.hdi.plot.0 <- ggplot(df0, aes(x = BF30.decision, y = HDI.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf.hdi.plot.0 <- 
  bf3.hdi.plot.0/
  bf10.hdi.plot.0/
  bf30.hdi.plot.0)

# For p values and HDI ---------------------------------------------------------
(hdi.p.plot.0 <- ggplot(df0, aes(x = HDI.decision, y = p.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

# For CI and HDI estimation ----------------------------------------------------
hdi.ci.plot.0 <- ggplot(df0, aes(x = HDI.est.correct, y = CI.est.correct)) + 
  geom_jitter(alpha = a, size = s) + 
  apatheme +
  scale_x_discrete(name = "HDI Inclusion",
                   labels = c("Not Included",
                              "Included")) +
  scale_y_discrete(name = "CI Inclusion",
                   labels = c("Not Included",
                              "Included"))
hdi.ci.plot.0
```

## Show corresponding conclusions for d = 0.5

```{r}
# Set alpha and size -----------------------------------------------------------
a <- 0.1
s <- 0.1

# For p values and Bayes factor cutoffs-----------------------------------------
(bf3.p.plot <- ggplot(df, aes(x = BF3.decision, y = p.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

(bf10.p.plot <- ggplot(df, aes(x = BF10.decision, y = p.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))
(bf30.p.plot <- ggplot(df, aes(x = BF30.decision, y = p.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf.p.plot <- 
  bf3.p.plot/
  bf10.p.plot/
  bf30.p.plot)

# For HDI and BF cutoffs --------------------------------------------------------

(bf3.hdi.plot <- ggplot(df, aes(x = BF3.decision, y = HDI.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

(bf10.hdi.plot <- ggplot(df, aes(x = BF10.decision, y = HDI.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf30.hdi.plot <- ggplot(df, aes(x = BF30.decision, y = HDI.decision)) + 
    geom_jitter(alpha = a, size = s) + 
    apatheme + 
    scale_fill_grey() + 
    facet_grid(cols = vars(n)))

(bf.hdi.plot <- 
  bf3.hdi.plot/
  bf10.hdi.plot/
  bf30.hdi.plot)

# For p values and HDI ---------------------------------------------------------
(hdi.p.plot <- ggplot(df, aes(x = HDI.decision, y = p.decision)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))

# For CI and HDI estimation ----------------------------------------------------
(hdi.ci.plot <- ggplot(df, aes(x = HDI.est.correct, y = CI.est.correct)) + 
   geom_jitter(alpha = a, size = s) + 
   apatheme + 
   scale_fill_grey() + 
   facet_grid(cols = vars(n)))
```

## Bar plots for corresponding conclusions at null

```{r}
ggplot(data = df0,
       aes(x = BF1.decision, fill = HDI.decision)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  ylab(label = "Percentage") +
  xlab(label = "Decision for Decision Rule BF > 1") +
  theme_apa()

```

## Bar plots for corresponding conclusions for alternative

```{r}
ggplot(data = df,
       aes(x = BF1.decision, fill = HDI.decision)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  ylab(label = "Percentage") +
  xlab(label = "Decision for Decision Rule BF > 1") +
  theme_apa()
```

# Compare estimation

Load a function that computed if intervals (CI and HDI) contain the mean of a next replication. For the last set in the data, the mean difference of the first row is used.

```{r}
source("interval_inclusion.R")
```

## Compare inclusion of parameter value of HDI and CI

```{r}
# calculate proportion of times parameter included in 
prop.param.ci.inclusion.null <- df0 %>%
  filter(.$CI.est.correct == "correct") %>%
  count() %>%
  {./nrow(df0)}

prop.param.hdi.inclusion.null <- df0 %>%
  filter(.$HDI.est.correct == "correct") %>%
  count() %>%
  {./nrow(df0)}

prop.param.ci.inclusion.alt <- df %>%
  filter(.$CI.est.correct == "correct") %>%
  count() %>%
  {./nrow(df)}

prop.param.hdi.inclusion.alt <- df %>%
  filter(.$HDI.est.correct == "correct") %>%
  count() %>%
  {./nrow(df)}

prop.param.ci.inclusion.null
prop.param.ci.inclusion.alt

prop.param.hdi.inclusion.null
prop.param.hdi.inclusion.alt
```

## Run computations of HDI and CI inclusion

```{r}
# Null
inc.null.10 <- interval_inclusion(df0[df0$n == 10,])

inc.null.10.ci <- inc.null.10[, 1] %>%
  table() %>%
  prop.table()

inc.null.10.hdi <- inc.null.10[, 2] %>%
  table() %>%
  prop.table()

inc.null.32 <- interval_inclusion(df0[df0$n == 32,])

inc.null.32.ci <- inc.null.32[, 1] %>%
  table() %>%
  prop.table()

inc.null.32.hdi <- inc.null.32[, 2] %>%
  table() %>%
  prop.table()

inc.null.64 <- interval_inclusion(df0[df0$n == 64,])

inc.null.64.ci <- inc.null.64[, 1] %>%
  table() %>%
  prop.table()

inc.null.64.hdi <- inc.null.64[, 2] %>%
  table() %>%
  prop.table()

inc.null.100 <- interval_inclusion(df0[df0$n == 100,])

inc.null.100.ci <- inc.null.100[, 1] %>%
  table() %>%
  prop.table()

inc.null.100.hdi <- inc.null.100[, 2] %>%
  table() %>%
  prop.table()

inc.null.300 <- interval_inclusion(df0[df0$n == 300,])

inc.null.300.ci <- inc.null.300[, 1] %>%
  table() %>%
  prop.table()

inc.null.300.hdi <- inc.null.300[, 2] %>%
  table() %>%
  prop.table()

inc.null.500 <- interval_inclusion(df0[df0$n == 500,])

inc.null.500.ci <- inc.null.500[, 1] %>%
  table() %>%
  prop.table()

inc.null.500.hdi <- inc.null.500[, 2] %>%
  table() %>%
  prop.table()


# Alt
inc.alt.10 <- interval_inclusion(df[df$n == 10,])

inc.alt.10.ci <- inc.alt.10[, 1] %>%
  table() %>%
  prop.table()

inc.alt.10.hdi <- inc.alt.10[, 2] %>%
  table() %>%
  prop.table()

inc.alt.32 <- interval_inclusion(df[df$n == 32,])

inc.alt.32.ci <- inc.alt.32[, 1] %>%
  table() %>%
  prop.table()

inc.alt.32.hdi <- inc.alt.32[, 2] %>%
  table() %>%
  prop.table()

inc.alt.64 <- interval_inclusion(df[df$n == 64,])

inc.alt.64.ci <- inc.alt.64[, 1] %>%
  table() %>%
  prop.table()

inc.alt.64.hdi <- inc.alt.64[, 2] %>%
  table() %>%
  prop.table()

inc.alt.100 <- interval_inclusion(df[df$n == 100,])

inc.alt.100.ci <- inc.alt.100[, 1] %>%
  table() %>%
  prop.table()

inc.alt.100.hdi <- inc.alt.100[, 2] %>%
  table() %>%
  prop.table()

inc.alt.300 <- interval_inclusion(df[df$n == 300,])

inc.alt.300.ci <- inc.alt.300[, 1] %>%
  table() %>%
  prop.table()

inc.alt.300.hdi <- inc.alt.300[, 2] %>%
  table() %>%
  prop.table()

inc.alt.500 <- interval_inclusion(df[df$n == 500,])

inc.alt.500.ci <- inc.alt.500[, 1] %>%
  table() %>%
  prop.table()

inc.alt.500.hdi <- inc.alt.500[, 2] %>%
  table() %>%
  prop.table()
```

## Visualization

Visualize inclusion of replication means in confidence and highest density intervals

```{r}
replication.inclusion.null <- data.frame(n = c(10, 32, 64, 100, 300, 500),
                                         ci.incl = c(inc.null.10.ci[1],
                                                     inc.null.32.ci[1],
                                                     inc.null.64.ci[1],
                                                     inc.null.100.ci[1],
                                                     inc.null.300.ci[2],
                                                     inc.null.500.ci[1]),
                                         hdi.incl = c(inc.null.10.hdi[1],
                                                      inc.null.32.hdi[1],
                                                      inc.null.64.hdi[1],
                                                      inc.null.100.hdi[1],
                                                      inc.null.300.hdi[2],
                                                      inc.null.500.hdi[1])) %>%
  ggplot(mapping = aes(x = n)) +
  geom_line(aes(y = ci.incl, color = "CI")) +
  geom_point(aes(y = ci.incl, color = "CI")) +
  geom_line(aes(y = hdi.incl, color = "HDI")) +
  geom_point(aes(y = hdi.incl, color = "HDI")) +
  scale_x_continuous(name = "Sample Size", 
                     breaks = c(10, 32, 64, 100, 300, 500)) +
  scale_y_continuous(name = "Proportion of Replication Mean Inclusion",
                     limits = c(0.8, 0.90)) +
  scale_color_manual(name = "Interval Type",
                     values = c("CI" = "red",
                                "HDI" = "blue"),
                     labels = c("CI",
                                "HDI")) +
  ggtitle(expression(delta~"= 0")) +
  apatheme

replication.inclusion.alt <- data.frame(n = c(10, 32, 64, 100, 300, 500),
                                        ci.incl = c(inc.alt.10.ci[1],
                                                    inc.alt.32.ci[1],
                                                    inc.alt.64.ci[2],
                                                    inc.alt.100.ci[1],
                                                    inc.alt.300.ci[1],
                                                    inc.alt.500.ci[2]),
                                        hdi.incl = c(inc.alt.10.hdi[1],
                                                     inc.alt.32.hdi[1],
                                                     inc.alt.64.hdi[2],
                                                     inc.alt.100.hdi[1],
                                                     inc.alt.300.hdi[1],
                                                     inc.alt.500.hdi[1])) %>%
  ggplot(mapping = aes(x = n)) +
  geom_line(aes(y = ci.incl, color = "CI")) +
  geom_point(aes(y = ci.incl, color = "CI")) +
  geom_line(aes(y = hdi.incl, color = "HDI")) +
  geom_point(aes(y = hdi.incl, color = "HDI")) +
  scale_x_continuous(name = "Sample Size", 
                     breaks = c(10, 32, 64, 100, 300, 500)) +
  scale_y_continuous(name = NULL,
                     limits = c(0.8, 0.90),
                     breaks = NULL) +
  scale_color_manual(name = "Interval Type",
                     values = c("CI" = "red",
                                "HDI" = "blue"),
                     labels = c("CI",
                                "HDI")) +
  ggtitle(expression(delta~"= 0.5")) +
  apatheme

replication.inclusion.null
replication.inclusion.alt

capture.percentage <-  replication.inclusion.null + replication.inclusion.alt + plot_layout(guides = "collect") 

capture.percentage
```

```{r}
# times in null situation the CI is correct and the HDI is incorrect
df0 %>%
  filter(HDI.est.correct == "incorrect",
         CI.est.correct == "correct") %>%
  nrow()

# times in null situation the HDI is correct and the CI is incorrect
df0 %>%
  filter(CI.est.correct == "incorrect",
         HDI.est.correct == "correct") %>%
  nrow()

# times in difference situation the p-value indicates a significant negative effect
df %>%
  filter(p.decision == "alt",
         diff_obs < 0)

# times in difference situation the BF indicates a significant negative effect
df %>%
  filter(BF1.decision == "alt",
         diff_obs < 0)
```


